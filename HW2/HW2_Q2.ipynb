{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "y_brQKHulSkz"
      },
      "outputs": [],
      "source": [
        "# Q-2)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load the CSV file\n",
        "file_path = \"/content/winequality-red.csv\"\n",
        "data = pd.read_csv(file_path, delimiter=';')\n",
        "\n",
        "data['quality'] = (data['quality'] > 6).astype(int)\n",
        "X = data.drop(columns=['quality']).values\n",
        "y = data['quality'].values\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-2(a)\n",
        "\n",
        "def holdout(model, X, y, testSize):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=42)\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
        "    test_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
        "    time_elapsed = time.time() - start_time\n",
        "    return train_auc, test_auc, time_elapsed\n",
        "\n",
        "model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5)\n",
        "holdout_results = holdout(model, X, y, testSize=0.2)\n",
        "\n",
        "print(\"Holdout Results:\")\n",
        "print(\"-\" * 15)\n",
        "print(\"Train AUC: {:.4f}\".format(holdout_results[0]))\n",
        "print(\"Test AUC:  {:.4f}\".format(holdout_results[1]))\n",
        "print(\"Time Elapsed: {:.4f} seconds\".format(holdout_results[2]))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-gCDDK6mPdU",
        "outputId": "9ded7869-b18c-4ad1-ac73-5d1072d22ccb"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Holdout Results:\n",
            "---------------\n",
            "Train AUC: 0.9255\n",
            "Test AUC:  0.8352\n",
            "Time Elapsed: 0.0120 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model shows strong performance on the training data (AUC = 0.93) and good\n",
        "generalization on the holdout test set (AUC = 0.84). The drop in AUC between\n",
        "training and test indicates mild overfitting, but overall the model maintains\n",
        "solid discriminatory power. The low runtime suggests the model is efficient\n",
        "and suitable for fast evaluation."
      ],
      "metadata": {
        "id": "L-RSnFb4ATZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q_2(b)\n",
        "def k_fold_cv(model, X, y, k):\n",
        "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    train_aucs, test_aucs = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        model.fit(X_train, y_train)\n",
        "        train_aucs.append(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]))\n",
        "        test_aucs.append(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "    time_elapsed = time.time() - start_time\n",
        "    return np.mean(train_aucs), np.mean(test_aucs), time_elapsed\n",
        "\n",
        "model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5)\n",
        "k_fold_results = k_fold_cv(model, X, y, k=5)\n",
        "\n",
        "print(\"K-Fold Cross Validation Results:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(\"Train AUC: {:.4f}\".format(k_fold_results[0]))\n",
        "print(\"Test AUC:  {:.4f}\".format(k_fold_results[1]))\n",
        "print(\"Time Elapsed: {:.4f} seconds\".format(k_fold_results[2]))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6WiHs7pmQfV",
        "outputId": "8907f608-fed8-4f2d-b2b1-71c26e9e5c70"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-Fold Cross Validation Results:\n",
            "----------------------------------------\n",
            "Train AUC: 0.9341\n",
            "Test AUC:  0.8379\n",
            "Time Elapsed: 0.0797 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Fold cross-validation results indicate consistently strong model performance.\n",
        "The high training AUC (0.93) and stable test AUC (0.84) suggest good\n",
        "generalization with limited overfitting. The slightly higher runtime reflects\n",
        "the added robustness gained from multiple validation folds."
      ],
      "metadata": {
        "id": "xZ-5VjYZF4Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-2(c)\n",
        "def monte_carlo_cv(model, X, y, testSize, s):\n",
        "    train_aucs, test_aucs = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for _ in range(s):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize,\n",
        "                                                            random_state=np.random.randint(10000))\n",
        "        model.fit(X_train, y_train)\n",
        "        train_aucs.append(roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]))\n",
        "        test_aucs.append(roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))\n",
        "\n",
        "    time_elapsed = time.time() - start_time\n",
        "    return np.mean(train_aucs), np.mean(test_aucs), time_elapsed\n",
        "\n",
        "model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=5)\n",
        "monte_carlo_results = monte_carlo_cv(model, X, y, testSize=0.2, s=10)\n",
        "\n",
        "print(\"Monte Carlo Cross Validation Results:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"Train AUC: {:.4f}\".format(monte_carlo_results[0]))\n",
        "print(\"Test AUC:  {:.4f}\".format(monte_carlo_results[1]))\n",
        "print(\"Time Elapsed: {:.4f} seconds\".format(monte_carlo_results[2]))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25W0LoZwmWn8",
        "outputId": "0ec43a3e-21c5-43b4-bb0b-65780f207ffa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monte Carlo Cross Validation Results:\n",
            "----------------------------------------\n",
            "Train AUC: 0.9320\n",
            "Test AUC:  0.8479\n",
            "Time Elapsed: 0.0873 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Monte Carlo cross-validation shows strong and stable model performance.\n",
        "The training AUC (0.93) and higher test AUC (0.85) indicate good\n",
        "generalization with minimal overfitting. The increased runtime reflects\n",
        "the repeated random sampling used to obtain a more reliable performance\n",
        "estimate."
      ],
      "metadata": {
        "id": "5U35_jjqGDtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-2(d)\n",
        "print(\"Summary Table:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Technique          | Train AUC | Test AUC | Time (s)\")\n",
        "print(\"-\" * 50)\n",
        "print(\"Holdout            | {:9.4f} | {:8.4f} | {:8.4f}\".format(*holdout_results))\n",
        "print(\"K-Fold (k=5)       | {:9.4f} | {:8.4f} | {:8.4f}\".format(*k_fold_results))\n",
        "print(\"Monte Carlo (s=10) | {:9.4f} | {:8.4f} | {:8.4f}\".format(*monte_carlo_results))\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Additional comparison insights\n",
        "print(\"\\nComparison Insights:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"1. Performance Comparison:\")\n",
        "print(f\"   - Highest Test AUC: {max(holdout_results[1], k_fold_results[1], monte_carlo_results[1]):.4f}\")\n",
        "print(f\"   - Lowest Test AUC:  {min(holdout_results[1], k_fold_results[1], monte_carlo_results[1]):.4f}\")\n",
        "print()\n",
        "\n",
        "print(\"2. Time Efficiency Comparison:\")\n",
        "print(f\"   - Fastest: {'Holdout' if holdout_results[2] <= k_fold_results[2] and holdout_results[2] <= monte_carlo_results[2] else 'K-Fold' if k_fold_results[2] <= monte_carlo_results[2] else 'Monte Carlo'}\")\n",
        "print(f\"   - Slowest: {'Holdout' if holdout_results[2] >= k_fold_results[2] and holdout_results[2] >= monte_carlo_results[2] else 'K-Fold' if k_fold_results[2] >= monte_carlo_results[2] else 'Monte Carlo'}\")\n",
        "print()\n",
        "\n",
        "print(\"3. Overfitting Assessment:\")\n",
        "print(f\"   - Train-Test Difference (Holdout): {holdout_results[0] - holdout_results[1]:.4f}\")\n",
        "print(f\"   - Train-Test Difference (K-Fold):  {k_fold_results[0] - k_fold_results[1]:.4f}\")\n",
        "print(f\"   - Train-Test Difference (Monte Carlo): {monte_carlo_results[0] - monte_carlo_results[1]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tjei2XqmZ8F",
        "outputId": "a9b3aa2d-adf5-462a-c109-138d5a6d150b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary Table:\n",
            "--------------------------------------------------\n",
            "Technique          | Train AUC | Test AUC | Time (s)\n",
            "--------------------------------------------------\n",
            "Holdout            |    0.9255 |   0.8352 |   0.0120\n",
            "K-Fold (k=5)       |    0.9341 |   0.8379 |   0.0797\n",
            "Monte Carlo (s=10) |    0.9320 |   0.8479 |   0.0873\n",
            "--------------------------------------------------\n",
            "\n",
            "Comparison Insights:\n",
            "----------------------------------------\n",
            "1. Performance Comparison:\n",
            "   - Highest Test AUC: 0.8479\n",
            "   - Lowest Test AUC:  0.8352\n",
            "\n",
            "2. Time Efficiency Comparison:\n",
            "   - Fastest: Holdout\n",
            "   - Slowest: Monte Carlo\n",
            "\n",
            "3. Overfitting Assessment:\n",
            "   - Train-Test Difference (Holdout): 0.0902\n",
            "   - Train-Test Difference (K-Fold):  0.0962\n",
            "   - Train-Test Difference (Monte Carlo): 0.0841\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the validation techniques, Monte Carlo cross-validation achieves the\n",
        "highest test AUC (0.848), indicating the best generalization performance,\n",
        "while Holdout yields the lowest test AUC (0.835) but is the most time-efficient.\n",
        "Trainâ€“test AUC gaps are comparable across methods, with Monte Carlo showing\n",
        "the smallest gap, suggesting slightly reduced overfitting. Overall, increased\n",
        "computational cost provides marginal but more reliable performance gains."
      ],
      "metadata": {
        "id": "VQS6W7NqGVBi"
      }
    }
  ]
}